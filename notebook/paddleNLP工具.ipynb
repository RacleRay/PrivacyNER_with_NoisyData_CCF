{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting lac\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/00/cf/36bbbfbeec33f40978c865ad9b899ab3dbed588a5f2b1bfdf5c363834c03/LAC-2.0.5.tar.gz (9.9MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0MB 12.8MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lac\n",
      "  Building wheel for lac (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lac: filename=LAC-2.0.5-py2.py3-none-any.whl size=9943586 sha256=aa9c1cf282d5686517e1f53006748905b7221ee7c52c3554d814bdb7acd04ad8\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/91/24/8d/9676708f8f7b1ca4d96c99021c388ffe130f00854e6af887ba\n",
      "Successfully built lac\n",
      "Installing collected packages: lac\n",
      "Successfully installed lac-2.0.5\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/LAC already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/LAC-2.0.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install lac -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting ddparser\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/42/e6/6a7cffabcc6defe27b91b051a7081855f6a28a7e2c7b1203f0a967646800/ddparser-0.1.1.tar.gz (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 12.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting LAC>=0.1.4 (from ddparser)\n",
      "Building wheels for collected packages: ddparser\n",
      "  Building wheel for ddparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ddparser: filename=ddparser-0.1.1-cp37-none-any.whl size=122632 sha256=8354a10f5f92a6da126426e9b70fecaa371bb72c09c89e5e5fe004824bb6eedf\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/1c/e4/4c/17a12dad929496285e6922015806429d23fa47946c18ed8139\n",
      "Successfully built ddparser\n",
      "Installing collected packages: LAC, ddparser\n",
      "Successfully installed LAC-2.0.5 ddparser-0.1.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/ddparser already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/LAC already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/ddparser-0.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/LAC-2.0.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ddparser -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.4'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "paddle.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAC工具\n",
    "\n",
    "https://github.com/baidu/lac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LAC', '是', '个', '优秀', '的', '分词', '工具'], ['百度', '是', '一家', '高科技', '公司']]\n"
     ]
    }
   ],
   "source": [
    "from LAC import LAC\n",
    "\n",
    "# 装载分词模型\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "# 单个样本输入，输入为Unicode编码的字符串\n",
    "text = u\"LAC是个优秀的分词工具\"\n",
    "seg_result = lac.run(text)\n",
    "\n",
    "# 批量样本输入, 输入为多个句子组成的list，平均速率会更快\n",
    "texts = [u\"LAC是个优秀的分词工具\", u\"百度是一家高科技公司\"]\n",
    "seg_result = lac.run(texts)\n",
    "\n",
    "print(seg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['LAC', '是', '个', '优秀', '的', '分词', '工具'], ['nz', 'v', 'q', 'a', 'u', 'n', 'n']], [['百度', '是', '一家', '高科技', '公司'], ['ORG', 'v', 'm', 'n', 'n']]]\n"
     ]
    }
   ],
   "source": [
    "# 装载LAC模型\n",
    "lac = LAC(mode='lac')\n",
    "\n",
    "# 单个样本输入，输入为Unicode编码的字符串\n",
    "text = u\"LAC是个优秀的分词工具\"\n",
    "lac_result = lac.run(text)\n",
    "\n",
    "# 批量样本输入, 输入为多个句子组成的list，平均速率更快\n",
    "texts = [u\"LAC是个优秀的分词工具\", u\"百度是一家高科技公司\"]\n",
    "lac_result = lac.run(texts)\n",
    "\n",
    "print(lac_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDParser\n",
    "\n",
    "https://github.com/baidu/ddparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddparser import DDParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-16 21:03:43,901-INFO: loading the fields.\n"
     ]
    }
   ],
   "source": [
    "ddp = DDParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': ['百度', '是', '一家', '高科技', '公司'],\n",
       "  'head': [2, 0, 5, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'ATT', 'ATT', 'VOB']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp.parse(\"百度是一家高科技公司\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': ['百度', '是', '一家', '高科技', '公司'],\n",
       "  'head': [2, 0, 5, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'ATT', 'ATT', 'VOB']},\n",
       " {'word': ['他', '送', '了', '一本', '书'],\n",
       "  'head': [2, 0, 2, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'MT', 'ATT', 'VOB']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp.parse([\"百度是一家高科技公司\", \"他送了一本书\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-16 21:04:33,106-INFO: loading the fields.\n"
     ]
    }
   ],
   "source": [
    "ddp = DDParser(prob=True, use_pos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': ['百度', '是', '一家', '高科技', '公司'],\n",
       "  'postag': ['ORG', 'v', 'm', 'n', 'n'],\n",
       "  'head': [2, 0, 5, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'ATT', 'ATT', 'VOB'],\n",
       "  'prob': [1.0, 1.0, 1.0, 1.0, 1.0]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp.parse([\"百度是一家高科技公司\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets=True, 数据集长度不均时处理速度更快\n",
    "#ddp = DDParser(buckets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': ['百度', '是', '一家', '高科技', '公司'],\n",
       "  'head': [2, 0, 5, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'ATT', 'ATT', 'VOB'],\n",
       "  'prob': [1.0, 1.0, 1.0, 1.0, 1.0]},\n",
       " {'word': ['他', '送', '了', '一本', '书'],\n",
       "  'head': [2, 0, 2, 5, 2],\n",
       "  'deprel': ['SBV', 'HED', 'MT', 'ATT', 'VOB'],\n",
       "  'prob': [1.0, 1.0, 1.0, 1.0, 1.0]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ddp.parse_seg([['百度', '是', '一家', '高科技', '公司'], ['他', '送', '了', '一本', '书']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senta\n",
    "情感分析和信息抽取\n",
    "https://github.com/baidu/Senta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/20/28/ff0d0936a31f15a0879caf6dac1f1cbaab1fc7b9e8baf8a1d5a70380fb22/regex-2020.11.13-cp37-cp37m-manylinux2010_x86_64.whl (667kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 21.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex\n",
      "Successfully installed regex-2020.11.13\n"
     ]
    }
   ],
   "source": [
    "!pip install regex -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting Senta\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/a8/d8/8b6a1a2c67405785e0c6d13a13bcb573688403b720bb005acc2863daec03/Senta-2.0.0-py3-none-any.whl (178kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.14.5 (from Senta)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/3f/e7/7f24ef402a5766c677683e313c5595137d754cb9eb1c99627803280e79d5/numpy-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2MB 11.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece==0.1.83 (from Senta)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/e8/cf/7089b87fdae8f47be81ce8e2e6377b321805c4648f2eb12fbd2987388dac/sentencepiece-0.1.83-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 14.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.20.4 (from Senta)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/87/6f/5863f1b27523c5d9f0ae2f3d07828ad383ceab39c79726d2ea4da7f679e7/scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4MB 22.9MB/s eta 0:00:01     |█                               | 163kB 22.9MB/s eta 0:00:01     |██████████▉                     | 1.8MB 22.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six==1.11.0 (from Senta)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting nltk==3.4.5 (from Senta)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 12.0MB/s eta 0:00:01     |█████▏                          | 235kB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.13.3 (from scikit-learn==0.20.4->Senta)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/dc/7e/8f6a79b102ca1ea928bae8998b05bf5dc24a90571db13cd119f275ba6252/scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 11.6MB/s eta 0:00:01   |                                | 51kB 15.7MB/s eta 0:00:02     |▊                               | 614kB 14.1MB/s eta 0:00:02     |█████████████████████████▎      | 20.5MB 9.2MB/s eta 0:00:01     |████████████████████████████▊   | 23.2MB 11.6MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449907 sha256=36d13d46e837600346c79f31d2b5c7d82bbbff363a137e583d87936a2a34b0e6\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/e0/99/95/e291e801fbca8c7bf3a4492bb5229872fcee133dd5086b4d6e\n",
      "Successfully built nltk\n",
      "\u001b[31mERROR: visualdl 2.0.3 has requirement six>=1.14.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: librosa 0.7.2 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: astroid 2.4.1 has requirement six~=1.12, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, sentencepiece, scipy, scikit-learn, six, nltk, Senta\n",
      "Successfully installed Senta-2.0.0 nltk-3.4.5 numpy-1.14.5 scikit-learn-0.20.4 scipy-1.5.4 sentencepiece-0.1.83 six-1.11.0\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Senta -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ernie_1.0_skep_large_ch', 'ernie_2.0_skep_large_en', 'roberta_skep_large_en']\n"
     ]
    }
   ],
   "source": [
    "from senta import Senta\n",
    "\n",
    "my_senta = Senta()\n",
    "\n",
    "# 获取目前支持的情感预训练模型, 我们开放了以ERNIE 1.0 large(中文)、ERNIE 2.0 large(英文)和RoBERTa large(英文)作为初始化的SKEP模型\n",
    "print(my_senta.get_support_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentiment_classify', 'aspect_sentiment_classify', 'extraction']\n"
     ]
    }
   ],
   "source": [
    "print(my_senta.get_support_task())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('中山大学是岭南第一学府', 'positive')]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "my_senta.init_model(model_class=\"ernie_1.0_skep_large_ch\", task=\"sentiment_classify\", use_cuda=use_cuda)\n",
    "texts = [\"中山大学是岭南第一学府\"]\n",
    "result = my_senta.predict(texts)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('百度是一家高科技公司', 'positive')]\n"
     ]
    }
   ],
   "source": [
    "# 预测中文评价对象级的情感分类任务\n",
    "my_senta.init_model(model_class=\"ernie_1.0_skep_large_ch\", task=\"aspect_sentiment_classify\", use_cuda=use_cuda)\n",
    "texts = [\"百度是一家高科技公司\"]\n",
    "aspects = [\"百度\"]\n",
    "result = my_senta.predict(texts, aspects)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('唐 家 三 少 ， 本 名 张 威 。', ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "# 预测中文观点抽取任务\n",
    "my_senta.init_model(model_class=\"ernie_1.0_skep_large_ch\", task=\"extraction\", use_cuda=use_cuda)\n",
    "texts = [\"唐 家 三 少 ， 本 名 张 威 。\"]\n",
    "result = my_senta.predict(texts)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 预测英文句子级情感分类任务（基于SKEP-ERNIE2.0模型）\n",
    "# my_senta.init_model(model_class=\"ernie_2.0_skep_large_en\", task=\"sentiment_classify\", use_cuda=use_cuda)\n",
    "# texts = [\"a sometimes tedious film .\"]\n",
    "# result = my_senta.predict(texts)\n",
    "# print(result)\n",
    "\n",
    "# # 预测英文评价对象级的情感分类任务（基于SKEP-ERNIE2.0模型）\n",
    "# my_senta.init_model(model_class=\"ernie_2.0_skep_large_en\", task=\"aspect_sentiment_classify\", use_cuda=use_cuda)\n",
    "# texts = [\"I love the operating system and the preloaded software.\"]\n",
    "# aspects = [\"operating system\"]\n",
    "# result = my_senta.predict(texts, aspects)\n",
    "# print(result)\n",
    "\n",
    "# # 预测英文观点抽取任务（基于SKEP-ERNIE2.0模型）\n",
    "# my_senta.init_model(model_class=\"ernie_2.0_skep_large_en\", task=\"extraction\", use_cuda=use_cuda)\n",
    "# texts = [\"The JCC would be very pleased to welcome your organization as a corporate sponsor .\"]\n",
    "# result = my_senta.predict(texts)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a sometimes tedious film .', 'negative')]\n",
      "[('I love the operating system and the preloaded software.', 'posative')]\n",
      "[('The JCC would be very pleased to welcome your organization as a corporate sponsor .', ['O', 'I_H', 'B_DS', 'B_DS', 'B_DS', 'B_DS', 'I_T', 'I_T', 'I_T', 'I_T', 'I_T', 'I_T', 'I_T', 'O', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "# 预测英文句子级情感分类任务（基于SKEP-RoBERTa模型）\n",
    "my_senta.init_model(model_class=\"roberta_skep_large_en\", task=\"sentiment_classify\", use_cuda=use_cuda)\n",
    "texts = [\"a sometimes tedious film .\"]\n",
    "result = my_senta.predict(texts)\n",
    "print(result)\n",
    "\n",
    "# 预测英文评价对象级的情感分类任务（基于SKEP-RoBERTa模型）\n",
    "my_senta.init_model(model_class=\"roberta_skep_large_en\", task=\"aspect_sentiment_classify\", use_cuda=use_cuda)\n",
    "texts = [\"I love the operating system and the preloaded software.\"]\n",
    "aspects = [\"operating system\"]\n",
    "result = my_senta.predict(texts, aspects)\n",
    "print(result)\n",
    "\n",
    "# 预测英文观点抽取任务（基于SKEP-RoBERTa模型）\n",
    "my_senta.init_model(model_class=\"roberta_skep_large_en\", task=\"extraction\", use_cuda=use_cuda)\n",
    "texts = [\"The JCC would be very pleased to welcome your organization as a corporate sponsor .\"]\n",
    "result = my_senta.predict(texts)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familia\n",
    "\n",
    "https://github.com/baidu/Familia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: paddlehub==1.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (3.12.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (0.1.85)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (3.4.5)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (1.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (1.15.0)\n",
      "Requirement already satisfied: visualdl>=2.0.0b in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (2.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (4.36.1)\n",
      "Requirement already satisfied: pandas; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (0.23.4)\n",
      "Requirement already satisfied: cma>=2.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (2.7.0)\n",
      "Requirement already satisfied: gunicorn>=19.10.0; sys_platform != \"win32\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (20.0.4)\n",
      "Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (1.1.1)\n",
      "Requirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (3.8.2)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (0.26.0)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.8.0) (4.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.6.0->paddlehub==1.8.0) (41.4.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (2.0.1)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (1.3.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (1.3.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (5.1.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (0.23)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (16.7.9)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (0.10.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.8.0) (1.4.10)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b->paddlehub==1.8.0) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b->paddlehub==1.8.0) (2.22.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b->paddlehub==1.8.0) (1.16.4)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b->paddlehub==1.8.0) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub==1.8.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub==1.8.0) (2.8.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.8.0) (2.10.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.8.0) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.8.0) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.8.0) (7.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.8.0) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.8.0) (2.6.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.8.0) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub==1.8.0) (0.6.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b->paddlehub==1.8.0) (2.8.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b->paddlehub==1.8.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b->paddlehub==1.8.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b->paddlehub==1.8.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b->paddlehub==1.8.0) (1.25.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==1.8.0) (1.1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub==1.8.0) (7.2.0)\n",
      "Downloading lda_news\n",
      "[==================================================] 100.00%\n",
      "Uncompress /home/aistudio/.paddlehub/tmp/tmp8tk9ifrt/lda_news\n",
      "[==================================================] 100.00%\n",
      "Successfully installed lda_news-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlehub==1.8.0\n",
    "!hub install lda_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-11-16 21:35:36,925] [    INFO] - Installing lda_news module\u001b[0m\n",
      "\u001b[32m[2020-11-16 21:35:36,939] [    INFO] - Module lda_news already installed in /home/aistudio/.paddlehub/modules/lda_news\u001b[0m\n",
      "\u001b[32m[2020-11-16 21:35:36,941] [    INFO] - Loading LDA config.\u001b[0m\n",
      "\u001b[32m[2020-11-16 21:35:37,456] [    INFO] - Loading word topic.\u001b[0m\n",
      "100%|██████████| 294657/294657 [00:10<00:00, 27373.59it/s]\n",
      "\u001b[32m[2020-11-16 21:35:48,295] [    INFO] - Model Info: #num_topics=2000 #vocab_size=294657 alpha=0.100000 beta=0.010000\u001b[0m\n",
      "\u001b[32m[2020-11-16 21:35:48,296] [    INFO] - Construct alias table for alias sampling method.\u001b[0m\n",
      "100%|██████████| 294657/294657 [00:16<00:00, 18084.24it/s]\n",
      "\u001b[32m[2020-11-16 21:36:05,833] [    INFO] - Installing lac module\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading lac\n",
      "[==================================================] 100.00%\n",
      "Uncompress /home/aistudio/.paddlehub/tmp/tmpx2_7m6zs/lac\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-11-16 21:36:07,217] [    INFO] - Successfully installed lac-2.2.0\u001b[0m\n",
      "\u001b[32m[2020-11-16 21:36:09,808] [    INFO] - Finish initialization.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddlehub as hub\n",
    "\n",
    "lda_news = hub.Module(name=\"lda_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003109487528061259\n",
      "0.057317150510233034\n"
     ]
    }
   ],
   "source": [
    "jsd, hd = lda_news.cal_doc_distance(doc_text1=\"今天的天气如何，适合出去游玩吗\", doc_text2=\"感觉今天的天气不错，可以出去玩一玩了\")\n",
    "print(jsd)\n",
    "print(hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03381290344402325\n",
      "0.06826390908033284\n"
     ]
    }
   ],
   "source": [
    "lda_sim = lda_news.cal_query_doc_similarity(query='百度搜索引擎', document='谷歌是全球最大的搜索引擎、致力于让网民更便捷地获取信息，找到所求。谷歌超过千亿的网页数据库，可以瞬间找到相关的搜索结果。')\n",
    "print(lda_sim)\n",
    "\n",
    "lda_sim = lda_news.cal_query_doc_similarity(query='百度搜索引擎', document='百度是全球最大的中文搜索引擎、致力于让网民更便捷地获取信息，找到所求。百度超过千亿的中文网页数据库，可以瞬间找到相关的搜索结果。')\n",
    "print(lda_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': '信息', 'similarity': 0.07019198271545816}, {'word': '超过', 'similarity': 0.04467743737347142}, {'word': '全球', 'similarity': 0.040603467534778774}, {'word': '相关', 'similarity': 0.030852776040970486}, {'word': '找到', 'similarity': 0.02577044528525854}, {'word': '搜索', 'similarity': 0.024027765903829726}, {'word': '获取', 'similarity': 0.016834583801086715}, {'word': '网民', 'similarity': 0.012986561972764637}, {'word': 'google', 'similarity': 0.004809742850722626}, {'word': '网页', 'similarity': 0.004186689256825968}]\n",
      "[{'word': '百度', 'similarity': 0.12943492762349573}, {'word': '信息', 'similarity': 0.06139783578769882}, {'word': '找到', 'similarity': 0.055296603463188265}, {'word': '搜索', 'similarity': 0.04270794098349327}, {'word': '全球', 'similarity': 0.03773627056367886}, {'word': '超过', 'similarity': 0.03478658388202199}, {'word': '相关', 'similarity': 0.026295857219683725}, {'word': '获取', 'similarity': 0.021313585287833996}, {'word': '中文', 'similarity': 0.020187103312009513}, {'word': '搜索引擎', 'similarity': 0.007092890537169911}]\n"
     ]
    }
   ],
   "source": [
    "results = lda_news.cal_doc_keywords_similarity('google是全球最大的搜索引擎、致力于让网民更便捷地获取信息，找到所求。google超过千亿的网页数据库，可以瞬间找到相关的搜索结果。')\n",
    "print(results)\n",
    "\n",
    "results = lda_news.cal_doc_keywords_similarity('百度是全球最大的中文搜索引擎、致力于让网民更便捷地获取信息，找到所求。百度超过千亿的中文网页数据库，可以瞬间找到相关的搜索结果。')\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
